% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  12pt,
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={BIO4158 Applied biostats with R},
  pdfauthor={Julien Martin},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
%\usepackage{booktabs}
\usepackage{ctable}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage[margin=2cm]{geometry}

\floatplacement{figure}{H}

%\usepackage[sf,bf]{titlesec}

\hypersetup{colorlinks=true, urlcolor=blue}

\renewcommand{\chaptername}{Chapitre}
\renewcommand{\contentsname}{Table des Mati√®res}
\renewcommand{\partname}{Partie}

\usepackage{framed,color}
\definecolor{incolor}{RGB}{240,240,240}
\definecolor{outcolor}{RGB}{248,248,248}

\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

%\renewenvironment{quote}{\begin{VF}}{\end{VF}}

\ifxetex
 \usepackage{letltxmacro}
 \setlength{\XeTeXLinkMargin}{1pt}
 \LetLtxMacro\SavedIncludeGraphics\includegraphics
 \def\includegraphics#1#{% #1 catches optional stuff (star/opt. arg.)
   \IncludeGraphicsAux{#1}%
 }%
 \newcommand*{\IncludeGraphicsAux}[2]{%
   \XeTeXLinkBox{%
     \SavedIncludeGraphics#1{#2}%
   }%
 }%
\fi

\makeatletter
\newenvironment{kframe}{%
\medskip{}
\setlength{\fboxsep}{.8em}
\def\at@end@of@kframe{}%
\ifinner\ifhmode%
 \def\at@end@of@kframe{\end{minipage}}%
 \begin{minipage}{\columnwidth}%
\fi\fi%
\def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
\colorbox{incolor}{##1}\hskip-\fboxsep
    % There is no \\@totalrightmargin, so:
    \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
\MakeFramed {\advance\hsize-\width
  \@totalleftmargin\z@ \linewidth\hsize
  \@setminipage}}%
{\par\unskip\endMakeFramed%
\at@end@of@kframe}
\makeatother

\makeatletter
\@ifundefined{Shaded}{
}{\renewenvironment{Shaded}{\begin{kframe}}{\end{kframe}}}
\makeatother

% \let\oldverbatim\verbatim
% \renewenvironment{Shaded}{\vspace{0.2cm}\begin{kframe}}{\end{kframe}}
% \renewenvironment{verbatim}{\begin{shaded}\begin{oldverbatim}}{\end{oldverbatim}\end{shaded}}

\newenvironment{rmdblock}[1]
 {
 \begin{itemize}
 \renewcommand{\labelitemi}{
   \raisebox{-.7\height}[0pt][0pt]{
     {\setkeys{Gin}{width=3em,keepaspectratio}\includegraphics{images/#1}}
   }
 }
 \begin{kframe}
 \setlength{\fboxsep}{1em}
 \item
 }
 {
 \end{kframe}
 \end{itemize}
 }
\newenvironment{rmdnote}
  {\begin{rmdblock}{note}}
  {\end{rmdblock}}
\newenvironment{rmdcaution}
  {\begin{rmdblock}{caution}}
  {\end{rmdblock}}
\newenvironment{rmdimportant}
  {\begin{rmdblock}{important}}
  {\end{rmdblock}}
\newenvironment{rmdtip}
  {\begin{rmdblock}{tip}}
  {\end{rmdblock}}
\newenvironment{rmdwarning}
  {\begin{rmdblock}{warning}}
  {\end{rmdblock}}
\newenvironment{rmdcode}
  {\begin{rmdblock}{screen}}
  {\end{rmdblock}}

\usepackage{makeidx}
\makeindex

\urlstyle{tt}

\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

% \frontmatter
\usepackage[]{natbib}
\bibliographystyle{plainnat}

\title{BIO4158 Applied biostats with R}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Laboratory manual}
\author{Julien Martin}
\date{21-09-2021}

\begin{document}
\maketitle

%\cleardoublepage\newpage\thispagestyle{empty}\null
%\cleardoublepage\newpage\thispagestyle{empty}\null
%\cleardoublepage\newpage
%\thispagestyle{empty}
%\begin{center}
%\includegraphics{images/missing.png}
%\end{center}

%\setlength{\abovedisplayskip}{-5pt}
%\setlength{\abovedisplayshortskip}{-5pt}

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{note}{%
\chapter*{Note}\label{note}}
\addcontentsline{toc}{chapter}{Note}

Development version. Lab material will appear slowly during the Fall 2021 term.

\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

The laboratory exercises outlined in the following pages are designed to allow you to develop some expertise in using statistical software (R)
to analyze data. R is powerful statistical software but, like all software, it has its limitations. In particular, it is dumb: it cannot think for you,
it cannot tell you whether the analysis you are attempting to do is appropriate or even makes any sense, and it cannot interpret your
results.

\hypertarget{general-points-to-keep-in-mind}{%
\section*{General points to keep in mind}\label{general-points-to-keep-in-mind}}
\addcontentsline{toc}{section}{General points to keep in mind}

\begin{itemize}
\item
  Before attempting any statistical procedure, you must familiarize yourself with what the procedure is actually doing. This does not mean you actually have to know the underlying mathematics (although this certainly helps!), but you should at least understand the principles involved in the analysis. Therefore, before doing a laboratory exercise, read the appropriate section(s) in the lecture notes. Otherwise, the output from your analyses - even if done correctly - will seem like drivel.
\item
  The laboratories are designed to complement the lectures, and vice versa. Owing to scheduling constraints, it may not be possible to synchronize the two perfectly. But feel free to bring questions about the laboratories to class, or questions about the lectures to the labs.
\item
  Work on the laboratories at your own speed: some can be donemuch more quickly than others, and one laboratory need not correspond to one laboratory session. In fact, for some laboratorieswe have allotted two laboratory sessions. Although you will notbe ``graded'' on the laboratories per se, be aware that completingthe labs is essential. If you do not complete the labs, it is veryunlikely that you will be able to complete the assignments and thefinal exam/term paper. So take these laboratories seriously!
\item
  The objective of the first lab is to allow you to acquire or reviewthe minimum knowledge required to complete the following laboratory exercises with R. There are always several methods toaccomplish something in R, but you will only find simple ways inthis manual. Those amongst you that want to go further will easilyfind many examples of more detailed and sophisticated methods.In particular, I point you to the following resources:

  \begin{itemize}
  \tightlist
  \item
    R for beginners
    \url{http://cran.r-project.org/doc/contrib/Paradis-rdebuts_en.pdf}
  \item
    An introduction to R
    \url{http://cran.r-project.org/doc/manuals/R-intro.html}
  \item
    If you prefer paper books, the CRAN web site has a commented list at :
    \url{http://www.r-project.org/doc/bib/R-books.html}
  \item
    Excellent list of R books
    \url{https://www.bigbookofr.com/}
  \item
    R reference card by Tom Short
    \url{http://cran.r-project.org/doc/contrib/Short-refcard.pdf}
  \end{itemize}
\end{itemize}

\hypertarget{what-is-r-and-why-use-it-in-this-course}{%
\section*{What is R and why use it in this course?}\label{what-is-r-and-why-use-it-in-this-course}}
\addcontentsline{toc}{section}{What is R and why use it in this course?}

R is multiplatform free software forming a system for statistical computation and graphics. R is also a programming language specially designed for statistical data analysis. It is a dialect of the S language. S- Plus is another dialect of the S language, very similar to R, incorporated into a commercial package. S-Plus has a built-in graphical design intreface that some find convivial.

R has 2 major advantages for this course. Initially, you will find that it also has one inconvenience. However, this ``inconvenience'' will rapidly force you to acquire very good working habits. So, I see it as a third advantage.

The first advantage is that you can install it freely on you personal computer(s). This is important because it is by doing analyses that you will learn and eventually master biostatistics. This implies that you have easy and unlimited access to a statistical software package. The second advantage is that R can do everything in statistics. R was conceived to be extensible and has become the preferred tool for statisticians around the world. The question is not ``Can R do this?'' but rather ``How can I do this in R?''. And search engine are your friends.

No other software package offers you these two advantages.

The inconvenience of R is that one has to type commands (or copy and paste code) rather than use a menu and select options. If you do not know what command to use, nothing will happen. It is therefore not that easy when you start. However, it is possible to rapidly learn to make basic operations (open a data file, plot data, and run a simple analysis). And once you understand the operating principle, you can easily find examples on the Web for more complex analyses and graphs for which you can adapt the code.

This is exactly what you will do in the first lab to familiarize yourself with R.

Why is this inconvenience really an advantage in my mind? Because this way of doing things is more efficient and will save you time on the long run. I guarantee it. Believe me, you will never do an analysis only once. As you'll proceed through analyses, you will find data entry errors, discover that the analysis must be run separately for subgroups, find extra data, have to rerun the analysis on transformed data, or you will make some analytical error along the way. If you use a graphical interface with menus, redoing an analysis implies that you reclick here, enter values there, select some options, etc. Each of these steps is a potential source of error. If, instead, you use lines of codes, you only have to fix the code and submit to repeat instantaneously the entire analysis. And you can perfectly document what you did, leaving an audit trail for the future. This is how pros work and can document the quality of the results of their analyses.

\hypertarget{software-installation}{%
\section*{Software installation}\label{software-installation}}
\addcontentsline{toc}{section}{Software installation}

\hypertarget{r}{%
\subsection*{R}\label{r}}
\addcontentsline{toc}{subsection}{R}

To install R on a computer, go to \url{http://cran.r-project.org/}. You will find compiled versions (binairies) for your preferred operating system (Windows, MacOS, Linux).

Note : R has already been installed on the lab computers (the version may be slightly different, but this should not matter).

\hypertarget{rstudio-or-vs-code}{%
\subsection*{Rstudio or VS code}\label{rstudio-or-vs-code}}
\addcontentsline{toc}{subsection}{Rstudio or VS code}

RStudio and VS code are integrated development environment software or IDE. RStudio was develop specifically to work with R. VScode is more generela but work extremely well with R. Both are available on Windows, OS X and Linux

\begin{itemize}
\tightlist
\item
  RStudio: \url{https://www.rstudio.com/products/rstudio/download/}
\item
  VScode: \url{https://code.visualstudio.com/download}
\end{itemize}

\hypertarget{r-libraries}{%
\subsection*{R libraries}\label{r-libraries}}
\addcontentsline{toc}{subsection}{R libraries}

R is essentially unlimited in terms of functions that can be used, because is relies on functions packages that can be added as extra components to use in R.

\begin{itemize}
\tightlist
\item
  Rmarkdown
\item
  tinytex
\end{itemize}

Those 2 packages should be installed automatically with RStudio but I recommend to install them manually in case they are not. To do so, just copy-paste the text below in R terminal.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"rmarkdown"}\NormalTok{, }\StringTok{"tinytex"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{gpower}{%
\subsection*{G*Power}\label{gpower}}
\addcontentsline{toc}{subsection}{G*Power}

G*Power est un programme gratuit, d√©velopp√© par des psychologues de l'Universit√© de Dusseldorf en Allemagne.
Le programme existe en version Mac et Windows.
Il peut cependant √™tre utilis√© sous linux via Wine.
G*Power vous permettra d'effectuer une analyse de puissance pour la majorit√© des tests que nous verrons au cours de la session sans avoir √† effectuer des calculs complexes ou farfouiller dans des tableaux ou des figures d√©crivant des distributions ou des courbes de puissance.

T√©l√©chargez le programme sur le site \url{https://www.psychologie.hhu.de/arbeitsgruppen/allgemeine-psychologie-und-arbeitspsychologie/gpower.html}

\hypertarget{general-laboratory-instructions}{%
\section*{General laboratory instructions}\label{general-laboratory-instructions}}
\addcontentsline{toc}{section}{General laboratory instructions}

\begin{itemize}
\tightlist
\item
  Bring a USB key or equivalent so you can save your work. Alternatively, email your results to yourself.
\item
  Read the lab exercise before coming to the lab. Read the R code and come with questions about the code.
\item
  During pre-labs, listen to the special instructions
\item
  Do the laboratory exercises at your own rhythm, in teams. Then, I
  recommend that you start (complete?) the lab assignment so that you can benefit from the presence of the TA or prof.
\item
  During your analyses, copy and paste results in a separate document, for example in your preferred word processing program. Annotate abundantly
\item
  Each time you shut down R, save the history of your commands (ex: labo1.1 rHistory, labo1.2.rHistory, etc). You will be able to redo the lab rapidly, get code fragments, or more easily identify errors.
\item
  Create your own ``library'' of code fragments (snippets). Annotate
  it abundantly. You will thank yourself later.
\end{itemize}

\hypertarget{notes-about-the-manual}{%
\section*{Notes about the manual}\label{notes-about-the-manual}}
\addcontentsline{toc}{section}{Notes about the manual}

You will find explanations on the theory, R code and functions, IDE best practice and exercises with R.

The manual tries to highlight some part of the text using the following boxes and icons.

\begin{rmdcode}
Exercises,
\end{rmdcode}

\begin{rmdcaution}
warnings,
\end{rmdcaution}

\begin{rmdwarning}
warnings,
\end{rmdwarning}

\begin{rmdimportant}
important points
\end{rmdimportant}

\begin{rmdnote}
notes
\end{rmdnote}

\begin{rmdtip}
and tips
\end{rmdtip}
\#\#\# Resources \{-\}

This document was developped using the excellent \href{https://bookdown.org/}{bookdown} üì¶ de \href{https://yihui.name/}{Yihui Xie}. The manual is based on the previous lab manual \emph{Findlay, Morin and Rundle, BIO4158 Laboratory manual for BIO4158}.

\hypertarget{license}{%
\subsection*{License}\label{license}}
\addcontentsline{toc}{subsection}{License}

The document is available follwoing the license \href{http://creativecommons.org/licenses/by-nc-sa/4.0/}{License Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International}.

\begin{figure}
\centering
\includegraphics{images/icons/license_cc.png}
\caption{License Creative Commons}
\end{figure}

\hypertarget{introduction-to-r}{%
\chapter{Introduction to R}\label{introduction-to-r}}

After completing this laboratory exercise, you should be able to:

\begin{itemize}
\tightlist
\item
  Open R data files
\item
  Import rectangular data sets
\item
  Export R data to text files
\item
  Verify that data were imported correctly
\item
  Examine the distribution of a variable
\item
  Examine visually and test for normality of a variable
\item
  Calculate descriptive statistics for a variable
\item
  Transform data
\end{itemize}

\hypertarget{set-intro}{%
\section{Packages and data needed for the lab}\label{set-intro}}

This labs needs the following:

\begin{itemize}
\tightlist
\item
  R packages:

  \begin{itemize}
  \tightlist
  \item
    ggplot2
  \end{itemize}
\item
  data files

  \begin{itemize}
  \tightlist
  \item
    ErablesGatineau.csv
  \item
    sturgeon.csv
  \end{itemize}
\end{itemize}

\hypertarget{importing-and-exporting-data}{%
\section{Importing and exporting data}\label{importing-and-exporting-data}}

There are multiple format to save data. The 2 most used formats with R are \texttt{.csv} and \texttt{.Rdata}.

\begin{itemize}
\tightlist
\item
  \texttt{.csv} files are used to store data in a simple format and are editable using any text editor (e.g.~Word, Writer, atom, \ldots) and spreadsheets (e.g.~MS Excel, LO Calc).
  They can be read using the function \texttt{read.csv()} and created in R with \texttt{write.csv()}.
\item
  \texttt{.Rdata} files are used to store not only data but any R object, however, those files can only be used in R. They are created using the \texttt{save()} function and read using the \texttt{load()} function.
\end{itemize}

Data for exercises and labs are provides in \texttt{.csv}.

\hypertarget{working-directory}{%
\subsection{Working directory}\label{working-directory}}

\begin{rmdwarning}
Potentially the most frequent error when starting with R is link to loading data or reading data from an external file in R.
\end{rmdwarning}

A typical error message is:

\begin{verbatim}
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'ou_est_mon_fichier.csv': No such file or directory
\end{verbatim}

This type of error simply means that R cannot find the file you specified. By default, when R starts, a folder is define as the based folder for R. This is the working directory. R by default will save any files in this folder and will start looking for files in this folder. So you need to specify to R where to look for files and where to save your files. This can be done in 3 different ways:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{file.choose()}. (not recommended, because not reproducible). This function will open a dialog box allowing you to click on the file you want. This is not recommended and can be long because you will have to do it absolutely every time you use R.
\item
  specify the complete path in the function. For example \texttt{read.csv("/home/julien/Documents/cours/BIO4558/labo/data/monfichier.csv")}. This is longer to type the first time and a bit tricky to get the correct path but after you can run the line of code and it works every time without trying to remember were you saved that damned file. However, this is specific to your own computer and would not work elsewhere.
\item
  specify a working directory with \texttt{setwd()}. This simplify tells R where to look for files and where to save files. (This is automatically done when using .Rmd files). Just set the working directory to where you want and after that all path will be relative to this working directory. The big advantage is that if you keep a similar folder structure for you R project it will be compatible and reproducible across all computer and OS
\end{enumerate}

To know which folder is the workind directory simply type \texttt{getwd()}

\begin{rmdtip}
When opening Rstudio by double-clicking on a file, it will automatically set the working irectory to the folder where this file is located. This can be super handy.
\end{rmdtip}

\begin{rmdimportant}
For all labs, I strongly recommend you to make a folder where you will save all your R scripts and data and use it as your working directory in R. For better organisation I suggest to save your data in a subfolder named \texttt{data\ All\ R\ code\ for\ data\ loading\ in\ the\ manual\ is\ based\ on\ that\ structure.\ This\ is\ why\ dat\ loading\ or\ saving\ code\ look\ like}data/my\_file.xxx`. If you follow it also all code for data loading can be simply copy-pasted and should work.
\end{rmdimportant}

\hypertarget{opening-a-.rdata-file}{%
\subsection{\texorpdfstring{Opening a \texttt{.Rdata} file}{Opening a .Rdata file}}\label{opening-a-.rdata-file}}

You can double-click on the file and R/Rstudio should open. Alternatively, you can use \texttt{load()} function and specify the names (and path) of the file. For example to load the data \texttt{ErablesGatineau.Rdata} in R which is located in the folder \texttt{data} in the working directory you can use:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{load}\NormalTok{(}\StringTok{"data/ErablesGatineau.Rdata"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{open-a-.csv-file}{%
\subsection{\texorpdfstring{Open a \texttt{.csv} file}{Open a .csv file}}\label{open-a-.csv-file}}

To import data saved in a \texttt{.csv} file, you need to use the \texttt{read.csv()} function.
For example, to create a R object named \texttt{erables} which contain the data from the file \texttt{ErablesGatineau.csv}, you need to use:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{erables \textless{}{-}}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/ErablesGatineau.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{rmdwarning}
Beware of the coma. If you are working in adifferent language (other than english), be careful because the decimal symbol might ot be the same.
By default R use the point for the decimal sign. If the dat use the coma for the decimal then R would not be able to read the file correctly. In this case you can use \texttt{read.csv2()} or \texttt{read.data()} which should solve the problem.
\end{rmdwarning}

To verify that the data were read and loaded properly, you can list all objects in memory with the \texttt{ls()} function, or get a more detailed description with \texttt{ls.str()}:

\begin{rmdtip}
I do not recommend to use \texttt{ls.str()} since it can produce really long R ouputs when you have multiple R object loaded.
I suggest instead to use the combination of \texttt{ls()} to get the list of all R objects and then \texttt{str()} only for the objects you want to look at.
\end{rmdtip}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ls}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "erables" "params"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{str}\NormalTok{(erables)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    100 obs. of  3 variables:
##  $ station: chr  "A" "A" "A" "A" ...
##  $ diam   : num  22.4 36.1 44.4 24.6 17.7 ...
##  $ biom   : num  732 1171 673 1552 504 ...
\end{verbatim}

R confirms that the object \texttt{erables}.
\texttt{erables} is a data.frame that contains 100 observations (lines) of 3 variables (columns) : \texttt{station} , a variable of type Factor with 2
levels, and \texttt{diam} and \texttt{biom} that are 2 numeric variables.

\hypertarget{entering-data-in-r}{%
\subsection{Entering data in R}\label{entering-data-in-r}}

R is not the ideal environment to input data. It is possible, but the syntax is heavy and makes most people upset. Use your preferred worksheet program instead. It will be more efficient and less frustrating.

\hypertarget{cleaning-up-correcting-data}{%
\subsection{Cleaning up / correcting data}\label{cleaning-up-correcting-data}}

Another operation that can be frustrating in R. Our advice: unless you want to keep track of all corrections made (so that you can go back to the original data), do not change data in R. Return to the original data file (in a worksheet or database), correct the data there, and then reimport into R. It is simple to resubmit the few lines of code to reimport data. Doing things this way will leave you with a single version of your data file that has all corrections, and the code that allows you to repeat the analysis exactly.

\hypertarget{exporting-data-from-r}{%
\subsection{Exporting data from R}\label{exporting-data-from-r}}

You have 2 options: export data in \texttt{.csv} or in \texttt{.Rdata}

To export in \texttt{.Rdata} use the function \texttt{save()} to export in \texttt{.csv} use \texttt{write.csv()}

For example, to save teh object \texttt{mydata} in a file \texttt{wonderful\_data.csv}that will be saved in your working directory you can type:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{write.csv}\NormalTok{(mydata, }\DataTypeTok{file =} \StringTok{"wonderful\_data.csv"}\NormalTok{, }\DataTypeTok{row.names =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{preliminary-examination-of-data}{%
\section{Preliminary examination of data}\label{preliminary-examination-of-data}}

The first step of data analysis is to examine the data at hand. This examination will tell you if the data were correctly imported, whether the numbers are credible, whether all data came in, etc. This initial data examination often will allow you to detect unlikely observations, possibly due to errors at the data entry stage. Finally, the initial plotting of the data will allow you to visualize the major trends that will be confirmed later by your statistical analysis.

The file \texttt{sturgeon.csv} contains data on sturgeons from the Saskatchewan River. These data were collected to examine how sturgeon size varies among sexes ( \texttt{sex} ), sites ( \texttt{location} ), and years( \texttt{year} ).

\begin{itemize}
\tightlist
\item
  Load the data from \texttt{sturgeon.csv} in a R object named \texttt{sturgeon}.
\item
  use the function \texttt{str()} to check that the data was loaded and read correctly.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sturgeon \textless{}{-}}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/sturgeon.csv"}\NormalTok{)}
\KeywordTok{str}\NormalTok{(sturgeon)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    186 obs. of  9 variables:
##  $ fklngth : num  37 50.2 28.9 50.2 45.6 ...
##  $ totlngth: num  40.7 54.1 31.3 53.1 49.5 ...
##  $ drlngth : num  23.6 31.5 17.3 32.3 32.1 ...
##  $ rdwght  : num  15.95 NA 6.49 NA 29.92 ...
##  $ age     : int  11 24 7 23 20 23 20 7 23 19 ...
##  $ girth   : num  40.5 53.5 31 52.5 50 54.2 48 28.5 44 39 ...
##  $ sex     : chr  "MALE" "FEMALE" "MALE" "FEMALE" ...
##  $ location: chr  "THE_PAS" "THE_PAS" "THE_PAS" "THE_PAS" ...
##  $ year    : int  1978 1978 1978 1978 1978 1978 1978 1978 1978 1978 ...
\end{verbatim}

\hypertarget{summary-statistics}{%
\subsection{Summary statistics}\label{summary-statistics}}

To get summary statistics on the contents of the data frame sturgeon, type the command:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(sturgeon)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     fklngth         totlngth        drlngth          rdwght     
##  Min.   :24.96   Min.   :28.15   Min.   :14.33   Min.   : 4.73  
##  1st Qu.:41.00   1st Qu.:43.66   1st Qu.:25.00   1st Qu.:18.09  
##  Median :44.06   Median :47.32   Median :27.00   Median :23.10  
##  Mean   :44.15   Mean   :47.45   Mean   :27.29   Mean   :24.87  
##  3rd Qu.:48.00   3rd Qu.:51.97   3rd Qu.:29.72   3rd Qu.:30.27  
##  Max.   :66.85   Max.   :72.05   Max.   :41.93   Max.   :93.72  
##                  NA's   :85      NA's   :13      NA's   :4      
##       age            girth           sex              location        
##  Min.   : 7.00   Min.   :11.50   Length:186         Length:186        
##  1st Qu.:17.00   1st Qu.:40.00   Class :character   Class :character  
##  Median :20.00   Median :44.00   Mode  :character   Mode  :character  
##  Mean   :20.24   Mean   :44.33                                        
##  3rd Qu.:23.50   3rd Qu.:48.80                                        
##  Max.   :55.00   Max.   :73.70                                        
##  NA's   :11      NA's   :85                                           
##       year     
##  Min.   :1978  
##  1st Qu.:1979  
##  Median :1979  
##  Mean   :1979  
##  3rd Qu.:1980  
##  Max.   :1980  
## 
\end{verbatim}

For each variable, R lists:

\begin{itemize}
\tightlist
\item
  the minimum
\item
  the maximum
\item
  the median that is the \(50^{th}\) percentile, here the \(93^{rd}\) value of the 186 observations ordered in ascending order
\item
  values at the first (25\%) and third quartile (75\%)
\item
  the number of missing values in the column.
\end{itemize}

Note that several variables have missing values (NA). Only the variables \texttt{fklngth} (fork length), \texttt{sex} , \texttt{location} , and \texttt{year} have 186 observations.

\begin{rmdwarning}
\textbf{Beware of missing values}

Several R functions are sensitive to missing values and you will frequently have to do your analyses on data subsets without missing data, or by using optional parameters in various commands. We will get back to this, but you should always pay attention and take note of missing data when you do analyses.
\end{rmdwarning}

\hypertarget{histogram-empirical-probability-density-boxplot-and-visual-assessment-of-normality}{%
\subsection{Histogram, empirical probability density, boxplot, and visual assessment of normality}\label{histogram-empirical-probability-density-boxplot-and-visual-assessment-of-normality}}

Let's look more closely at the distribution of \texttt{fklngth}.
The command \texttt{hist()} will create a histogram. For the histogram of \texttt{fklngth} in the \texttt{sturgeon} data frame, type the command:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{(sturgeon}\OperatorTok{$}\NormalTok{fklngth)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{Labs_BIO4158_files/figure-latex/hist-stur-1.pdf}
\caption{\label{fig:hist-stur}Histogram of fluke length of sturgeons}
\end{figure}

The data appear to be approximately normal. This is good to know.

\begin{rmdnote}
Note that this syntax is a bit heavy as you need to prefix variable names by the data frame name \texttt{sturgeon\$}. You can lighten the syntax by making the variables directly accessible by commands by typing the command \texttt{attach()}.
However, I \textbf{strongly recommend not to use} it because it can lead to many problems hard to detect compare to the little benfit is provides
\end{rmdnote}

This histogram (Fig. \ref{fig:hist-stur}) is a very classical representation of the distribution. Histograms are not perfect however because their shape partly depends on the number of bins used, more so for small samples. One can do better, especially if you want to visually compare the observed distribution to a normal distribution. But you need to come up with a bit of extra R code based on the \texttt{ggplot2} üì¶.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# load ggplot2 if needed}
\KeywordTok{library}\NormalTok{(ggplot2)}

\CommentTok{\#\# use "sturgeon" dataframe to make plot called mygraph}
\CommentTok{\# and define x axis as representing fklngth}
\NormalTok{mygraph \textless{}{-}}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ sturgeon, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ fklngth))}

\CommentTok{\#\# add data to the mygraph ggplot}
\NormalTok{mygraph \textless{}{-}}\StringTok{ }\NormalTok{mygraph }\OperatorTok{+}
\StringTok{  }\CommentTok{\#\# add semitransparent histogram}
\StringTok{  }\KeywordTok{geom\_histogram}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ ..density..),}
    \DataTypeTok{bins =} \DecValTok{30}\NormalTok{, }\DataTypeTok{color =} \StringTok{"black"}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.3}
\NormalTok{  ) }\OperatorTok{+}
\StringTok{  }\CommentTok{\#\#  add density smooth}
\StringTok{  }\KeywordTok{geom\_density}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\CommentTok{\#\# add observations positions or rug bars}
\StringTok{  }\KeywordTok{geom\_rug}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\CommentTok{\#\# add Gaussian curve adjusted to the data with mean and sd from fklngth}
\StringTok{  }\KeywordTok{stat\_function}\NormalTok{(}
    \DataTypeTok{fun =}\NormalTok{ dnorm,}
    \DataTypeTok{args =} \KeywordTok{list}\NormalTok{(}
      \DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(sturgeon}\OperatorTok{$}\NormalTok{fklngth),}
      \DataTypeTok{sd =} \KeywordTok{sd}\NormalTok{(sturgeon}\OperatorTok{$}\NormalTok{fklngth)}
\NormalTok{    ),}
    \DataTypeTok{color =} \StringTok{"red"}
\NormalTok{  )}

\CommentTok{\#\# display graph}
\NormalTok{mygraph}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{Labs_BIO4158_files/figure-latex/stur-g1-1.pdf}
\caption{\label{fig:stur-g1}Distribution of fluke length in sturgeon plotted with ggplot}
\end{figure}

Each observation is represented by a short vertical bar below the x- axis (rug). The red line is the normal distribution with the same mean and standard deviation as the data. The other line is the empirical distribution, smoothed from the observations.

The ggplot object you just created (\texttt{mygraph}) can be further manipulated. For example, you can plot the distribution of \texttt{fklngth} per \texttt{sex} and \texttt{year} groups simply by adding a \texttt{facet\_grid()} statement:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mygraph }\OperatorTok{+}\StringTok{ }\KeywordTok{facet\_grid}\NormalTok{(year }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{sex)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Labs_BIO4158_files/figure-latex/aventure-1.pdf}

Each panel contains the data distribution for one sex that year, and the recurring red curve is the normal distribution for the entire data set. It can serve as a reference to help visually evaluate differences among panels.

Another way to visually assess normality of data is the QQ plot that is
obtained by the pair of commands \texttt{qqnorm()} and \texttt{qqline()}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qqnorm}\NormalTok{(sturgeon}\OperatorTok{$}\NormalTok{fklngth)}
\KeywordTok{qqline}\NormalTok{(sturgeon}\OperatorTok{$}\NormalTok{fklngth)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Labs_BIO4158_files/figure-latex/stur-norm-1.pdf}
Perfectly normal data would follow the straight diagonal line. Here there are deviations in the tails of the distribution and a bit to the right of the center.
Compare this representation to the two preceding graphs.
You will probably agree that it is easier to visualize how data deviate from normality by looking at a histogram of an empirical probability density than by looking at the QQ plots.
However, QQ plots are often automatically produced by various statistical routines and you should be able to interpret them.
In addition, one can easily run a formal test of normality in R with the command \texttt{shapiro.test()} that computes a statistic (\texttt{W}) that measures how tightly data fall around the straight diagonal line of the QQ plot. If data fall perfectly on the line, then \texttt{W\ =\ 1}. If \texttt{W} is much less than 1, then data are not normal.

For the \texttt{fklngth} data:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{shapiro.test}\NormalTok{(sturgeon}\OperatorTok{$}\NormalTok{fklngth)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Shapiro-Wilk normality test
## 
## data:  sturgeon$fklngth
## W = 0.97225, p-value = 0.0009285
\end{verbatim}

W is close to 1, but far enough to indicate a statistically significant deviation from normality.

Visual examination of very large data sets is often made difficult by the superposition of data points. Boxplots are an interesting alternative.
The command \texttt{boxplot(fklngth\textasciitilde{}sex,\ notch=TRUE)} produces a boxplot of \texttt{fklngth} for each \texttt{sex} , and adds whiskers.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{boxplot}\NormalTok{(fklngth }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{sex, }\DataTypeTok{data =}\NormalTok{ sturgeon, }\DataTypeTok{notch =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{Labs_BIO4158_files/figure-latex/boxplot-stur-1.pdf}
\caption{\label{fig:boxplot-stur}Boxplot of fluke length in strugeon by sex}
\end{figure}

The slightly thicker line inside the box of figure \ref{fig:boxplot-stur} indicates the median.
The width of the notch is proportional to the uncertainty around the median estimate.
One can visually assess the approximate statistical significance of differences among medians by looking at the overlap of the notches (here there is no overlap and one could tentatively conclude that the median female size is larger than the median male size).
Boxes extend from the first to third quartile (the 25\textsuperscript{th} to 75\textsuperscript{th} percentile if you prefer).
Bars (whiskers) extend above and below the boxes from the minimum to the maximum observed value or, if there are extreme values, from the smallest to the largest observed value within 1.5x the interquartile range from the median. Observations exceeding the limits of the whiskers (hence further away from the median than 1.5x the interquartile range, the range between the 25\textsuperscript{th} and 75\textsuperscript{th} percentile) are plotted as circles. These are outliers, possibly aberrant data.

\hypertarget{scatterplots}{%
\subsection{Scatterplots}\label{scatterplots}}

In addition to histograms and other univariate plots, it is often informative to examine scatter plots.
The command \texttt{plot(y\textasciitilde{}x)} produces a scatter plot of y on the vertical axis (the ordinate) vs x on the horizontal axis (abscissa).

\begin{rmdcode}
Create a scatterplot of fklngth vs age using the plot() command.
\end{rmdcode}

You should obtain:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(fklngth }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{age, }\DataTypeTok{data =}\NormalTok{ sturgeon)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Labs_BIO4158_files/figure-latex/stur-biv-plot-1.pdf}

R has a function to create all pairwise scatterplots rapidly called
\texttt{pairs()} . One of \texttt{pairs()} options is the addition of a lowess trace on
each plot to that is a smoothed trend in the data.
To get the plot matrix with the lowess smooth for all variables in the
sturgeon data frame, execute the command
\texttt{pairs(sturgeon,\ panel=panel.smooth)}. Howeber given the large number of variable in \texttt{sturgeon} we can limit the plot to the first 6 columns in the data.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pairs}\NormalTok{(sturgeon[, }\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{], }\DataTypeTok{panel =}\NormalTok{ panel.smooth)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Labs_BIO4158_files/figure-latex/pairs-stur-1.pdf}

\hypertarget{creating-data-subsets}{%
\section{Creating data subsets}\label{creating-data-subsets}}

You will frequently want to do analyses on some subset of your data.
The command \texttt{subset()} is what you need to isolate cases meeting some criteria.
For example, to create a subset of the sturgeon data frame that contains only females caught in 1978, you could write:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sturgeon\_female\_}\DecValTok{1978}\NormalTok{ \textless{}{-}}\StringTok{ }\KeywordTok{subset}\NormalTok{(sturgeon, sex }\OperatorTok{==}\StringTok{ "FEMALE"} \OperatorTok{\&}\StringTok{ }\NormalTok{year }\OperatorTok{==}\StringTok{ "1978"}\NormalTok{)}
\NormalTok{sturgeon\_female\_}\DecValTok{1978}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      fklngth totlngth  drlngth rdwght age girth    sex   location year
## 2   50.19685 54.13386 31.49606     NA  24  53.5 FEMALE    THE_PAS 1978
## 4   50.19685 53.14961 32.28346     NA  23  52.5 FEMALE    THE_PAS 1978
## 6   49.60630 53.93701 31.10236  35.86  23  54.2 FEMALE    THE_PAS 1978
## 7   47.71654 51.37795 33.97638  33.88  20  48.0 FEMALE    THE_PAS 1978
## 15  48.89764 53.93701 29.92126  35.86  23  52.5 FEMALE    THE_PAS 1978
## 105 46.85039       NA 28.34646  23.90  24    NA FEMALE CUMBERLAND 1978
## 106 40.74803       NA 24.80315  17.50  18    NA FEMALE CUMBERLAND 1978
## 107 40.35433       NA 25.59055  20.90  21    NA FEMALE CUMBERLAND 1978
## 109 43.30709       NA 27.95276  24.10  19    NA FEMALE CUMBERLAND 1978
## 113 53.54331       NA 33.85827  48.90  20    NA FEMALE CUMBERLAND 1978
## 114 51.77165       NA 31.49606  35.30  26    NA FEMALE CUMBERLAND 1978
## 116 45.27559       NA 26.57480  23.70  24    NA FEMALE CUMBERLAND 1978
## 118 53.14961       NA 32.67717  45.30  25    NA FEMALE CUMBERLAND 1978
## 119 50.19685       NA 32.08661  33.90  26    NA FEMALE CUMBERLAND 1978
## 123 49.01575       NA 29.13386  37.50  22    NA FEMALE CUMBERLAND 1978
\end{verbatim}

\begin{rmdcaution}
When using criteria to select cases, be careful of the \texttt{==} syntax to mean equal to.
In this context, if you use a single \texttt{=}, you will not get what you want.
The following table lists the most common criteria to create expressions and their R syntax.
\end{rmdcaution}

\begin{longtable}[]{@{}llll@{}}
\toprule
Operateur & Explication & Operateur & Explication\tabularnewline
\midrule
\endhead
== & Equal to & != & Not equal to\tabularnewline
\textgreater{} & Larger than & \textless{} & Lower than\tabularnewline
\textgreater= & Larger than or equal to & \textless= & Lower than or equal to\tabularnewline
\& & And (vectorized) & \textbar{} & Or (vectorized)\tabularnewline
\&\& & And (control) & \textbar\textbar{} & Or (control)\tabularnewline
! & Not & &\tabularnewline
\bottomrule
\end{longtable}

\begin{rmdcode}
Using the commands \texttt{subset()} and \texttt{hist()} , create a histogram for females caught in 1979 and 1980 (hint: \texttt{sex=="FEMALE"\ \&\ (year\ =="1979"\ \textbar{}\ year=="1980")})
\end{rmdcode}

\begin{figure}
\centering
\includegraphics{Labs_BIO4158_files/figure-latex/intror-subex-1.pdf}
\caption{\label{fig:intror-subex}Distibution of fluke length of female sturgeons in 1979 and 1980}
\end{figure}

\hypertarget{data-transformation}{%
\section{Data transformation}\label{data-transformation}}

You will frequently transform raw data to better satisfy assumptions of statistical tests. R will allow you to do that easily.
The most used functions are probably:

\begin{itemize}
\tightlist
\item
  \texttt{log()}
\item
  \texttt{sqrt()}
\item
  \texttt{ifelse()}
\end{itemize}

You can use these functions directly within commands, create vector variables, or add columns in data frames.
To do a plot of the decimal log of fklngth vs age, you can simply use the \texttt{log10()} function within the plot command:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(}\KeywordTok{log10}\NormalTok{(fklngth)}\OperatorTok{\textasciitilde{}}\NormalTok{age, }\DataTypeTok{data =}\NormalTok{ sturgeon)}
\end{Highlighting}
\end{Shaded}

To create a vector variable, an orphan variable if you wish, one that is not part of a data frame, called \texttt{lfklngth} and corresponding too the decimal log of \texttt{fklngth}, simply enter:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{logfklngth \textless{}{-}}\StringTok{ }\KeywordTok{log10}\NormalTok{(sturgeon}\OperatorTok{$}\NormalTok{fklngth)}
\end{Highlighting}
\end{Shaded}

If you want this new variable to be added to a data frame, then you must prefix the variable name by the data frame name and the \texttt{\$} symbol.
For example to add the variable \texttt{lfkl} containing the decimal log of \texttt{fklngth} to the \texttt{sturgeon} data frame, enter:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sturgeon}\OperatorTok{$}\NormalTok{lfkl \textless{}{-}}\StringTok{ }\KeywordTok{log10}\NormalTok{(sturgeon}\OperatorTok{$}\NormalTok{fklngth)}
\end{Highlighting}
\end{Shaded}

\texttt{lfkl} will be added to the data frame \texttt{sturgeon} for the R session.
Do not forget to save the modified data frame if you want to keep the modified version. Or better, save you Rscript and do not forget to run the line of code again next time you need it.

For conditional transformations, you can use the function \texttt{ifelse()}.
For example, to create a new variable called dummy with a value of 1 for males and 0 for females, you can use:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sturgeon}\OperatorTok{$}\NormalTok{dummy \textless{}{-}}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(sturgeon}\OperatorTok{$}\NormalTok{sex }\OperatorTok{==}\StringTok{ "MALE"}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{exercice}{%
\section{Exercice}\label{exercice}}

The file \texttt{salmonella.csv} contains numerical values for the variable
called ratio for two environments (\texttt{milieu}: \texttt{IN\ VITRO} or \texttt{IN\ VIVO})
and for 3 strains (\texttt{souche}).
Examine the ratio variable and make a graph to visually assess normality for the wild (SAUVAGE) strain.

\begin{figure}
\centering
\includegraphics{Labs_BIO4158_files/figure-latex/intror-exer-1.pdf}
\caption{\label{fig:intror-exer}Distibution of infection ratios by the wild (SAUVAGE) strain of salmonella}
\end{figure}

\printindex

\end{document}
